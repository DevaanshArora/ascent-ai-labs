from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from fastapi import HTTPException
import json

class ChatService:
    def __init__(self, openai_api_key: str):
        self.model = ChatOpenAI(
            model_name="gpt-4o-mini", 
            temperature=0.7, 
            openai_api_key=openai_api_key
        )
        self.chat_histories = {}

    def initialize_session(self, session_id: str):
        if session_id not in self.chat_histories:
            self.chat_histories[session_id] = [
                SystemMessage(content=(
                    "You are a GRC policy generator. Based on the provided input, generate a detailed and structured "
                    "organizational policy in JSON format. The output must be comprehensive, practical, and ready to use, "
                    "Ensure the JSON format is flat, and do not wrap the content under a "
                    "single parent key such as 'Policy'. Each section should stand alone as a top-level key.Please take reference from the input fields entered by the user, The policy should be around 1200 words."
                ))
            ]

    def generate_policy(self, session_id: str, user_query: str):
        self.initialize_session(session_id)
        chat_history = self.chat_histories[session_id]
        chat_history.append(HumanMessage(content=user_query))

        try:
            result = self.model.invoke(chat_history)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
        
        try:
            response = json.loads(result.content)
        except json.JSONDecodeError:
            raise HTTPException(status_code=500, detail="Invalid JSON format generated by the model.")
        
        chat_history.append(AIMessage(content=result.content))
        return response
